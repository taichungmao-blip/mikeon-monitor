import requests
from bs4 import BeautifulSoup
import os
import json
import re
from datetime import datetime

# ================= è¨­å®šå€ =================
BASE_URL = "https://stocks.ddns.net/Forum/128/mikeon88%E6%8C%81%E8%82%A1%E5%A4%A7%E5%85%AC%E9%96%8B.aspx"
STATUS_FILE = "status.json"
DISCORD_WEBHOOK_URL = os.environ.get("DISCORD_WEBHOOK")

# æ¸¬è©¦ç”¨çš„è¶…å¤§é ç¢¼ (æ•…æ„è¶…é 23)
OVERSHOOT_PAGE = 200 

HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
}
# ==============================================

def send_discord_notify(message_content, post_time, url):
    if not DISCORD_WEBHOOK_URL:
        print("âŒ æœªè¨­å®š Discord Webhook")
        return

    preview = message_content[:300] + "..." if len(message_content) > 300 else message_content
    
    data = {
        "username": "Mikeon88 è¿½è¹¤å™¨",
        "embeds": [{
            "title": "ğŸš¨ Mikeon88 æœ‰æ–°ç™¼è¨€ï¼",
            "description": preview,
            "url": url,
            "color": 15158332, 
            "fields": [
                {"name": "ç™¼è¨€æ™‚é–“", "value": post_time, "inline": True},
                {"name": "ä¾†æºé€£çµ", "value": f"[é»æ“Šå‰å¾€]({url})", "inline": True}
            ],
            "footer": {
                "text": "V6 è¶…é€Ÿè·³èºç‰ˆ"
            }
        }]
    }
    try:
        requests.post(DISCORD_WEBHOOK_URL, json=data)
        print("âœ… Discord é€šçŸ¥å·²ç™¼é€")
    except Exception as e:
        print(f"âŒ ç™¼é€å¤±æ•—: {e}")

def load_status():
    if os.path.exists(STATUS_FILE):
        with open(STATUS_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    return {"last_fingerprint": ""}

def save_status(fingerprint):
    with open(STATUS_FILE, "w", encoding="utf-8") as f:
        json.dump({"last_fingerprint": fingerprint}, f, ensure_ascii=False, indent=4)

def get_real_last_page_number(session):
    """
    ä½¿ç”¨ã€Œè¶…é€Ÿè·³èºæ³•ã€æ‰¾å‡ºçœŸæ­£çš„æœ€å¾Œä¸€é 
    """
    print(f"ğŸ•µï¸ å˜—è©¦æ¢æ¸¬æœ€å¾Œä¸€é  (è«‹æ±‚ Page {OVERSHOOT_PAGE})...")
    
    target_url = f"{BASE_URL}?page={OVERSHOOT_PAGE}"
    try:
        res = session.get(target_url, headers=HEADERS, timeout=20)
        soup = BeautifulSoup(res.text, "html.parser")
        
        # 1. æª¢æŸ¥é€™å€‹é é¢æœ‰æ²’æœ‰ç™¼è¨€ï¼Ÿ
        # å¦‚æœæœ‰ç™¼è¨€ï¼Œä»£è¡¨ç¶²ç«™è‡ªå‹•æŠŠæˆ‘å€‘å°å‘äº†æœ€å¾Œä¸€é  (Case 1)
        posts = soup.find_all("div", class_="post-body")
        if posts:
            print("ğŸš€ ç¶²ç«™è‡ªå‹•å°å‘æœ‰æ•ˆé é¢ï¼Œåˆ†æåˆ†é ä¸­...")
        
        # 2. ä¸ç®¡å…§å®¹æ˜¯ä¸æ˜¯ç©ºçš„ï¼Œæˆ‘å€‘éƒ½æª¢æŸ¥åˆ†é åˆ—
        # ç•¶æˆ‘å€‘è«‹æ±‚ Page 200 æ™‚ï¼Œåˆ†é åˆ—é€šå¸¸æœƒé¡¯ç¤º [21] [22] [23]
        max_page = 1
        links = soup.find_all("a", href=True)
        for link in links:
            txt = link.get_text(strip=True)
            if txt.isdigit():
                val = int(txt)
                if val > max_page:
                    max_page = val
        
        print(f"ğŸ“Š åµæ¸¬åˆ°æœ€å¤§é æ•¸ç‚º: {max_page}")
        return max_page, soup # å›å‚³ soup ä»¥ä¾¿å¦‚æœå·²ç¶“åœ¨æœ€å¾Œä¸€é å°±ä¸ç”¨é‡æŠ“
        
    except Exception as e:
        print(f"âš ï¸ æ¢æ¸¬å¤±æ•—: {e}")
        return 1, None

def extract_time(container):
    """
    å¢å¼·ç‰ˆæ™‚é–“æŠ“å–ï¼šå…ˆæ‰¾æ¨™ç±¤ï¼Œæ‰¾ä¸åˆ°å°±ç”¨æ­£è¦è¡¨é”å¼æƒæå…¨æ–‡
    """
    # æ–¹æ³• 1: æ¨™æº–æ¨™ç±¤
    time_span = container.find("span", class_="local-time")
    if time_span:
        return time_span.text.strip()
    
    # æ–¹æ³• 2: å…¨æ–‡æƒæ (é‡å°èˆŠæ–‡ç« æˆ–çµæ§‹æ”¹è®Š)
    text = container.get_text()
    # å°‹æ‰¾é¡ä¼¼ 2025/12/13 10:49:42 çš„æ ¼å¼
    match = re.search(r'\d{4}/\d{1,2}/\d{1,2}\s+\d{1,2}:\d{1,2}:\d{1,2}', text)
    if match:
        return match.group(0)
    
    return "æœªçŸ¥æ™‚é–“"

def main():
    print(f"ğŸš€ V6 å•Ÿå‹•æª¢æŸ¥: {datetime.now()}")
    
    status = load_status()
    last_fingerprint = status["last_fingerprint"]
    
    session = requests.Session()
    
    # æ­¥é©Ÿ 1: æ‰¾å‡ºçœŸæ­£çš„æœ€å¾Œä¸€é 
    real_page, soup_cache = get_real_last_page_number(session)
    
    # æ­¥é©Ÿ 2: é–å®šç›®æ¨™
    target_url = f"{BASE_URL}?page={real_page}"
    print(f"ğŸ¯ é–å®šæœ€çµ‚ç›®æ¨™: {target_url}")
    
    # å¦‚æœå‰›å‰›æ¢æ¸¬æ™‚æ‹¿åˆ°çš„é é¢ä¸ç­‰æ–¼æœ€å¾Œä¸€é ï¼Œå°±è¦é‡æ–°æŠ“å–
    # (ä¾‹å¦‚å‰›å‰›æ¢æ¸¬åˆ°åˆ†é åˆ—é¡¯ç¤º 23ï¼Œä½†å…§å®¹æ˜¯ç©ºçš„ï¼Œæˆ‘å€‘ç¾åœ¨è¦çœŸçš„å»æŠ“ Page 23)
    if not soup_cache or "page=" not in str(real_page): # ç°¡å–®åˆ¤æ–·ï¼Œç›´æ¥é‡æŠ“æœ€ä¿éšª
        res = session.get(target_url, headers=HEADERS, timeout=20)
        res.encoding = 'utf-8'
        soup = BeautifulSoup(res.text, "html.parser")
    else:
        soup = soup_cache

    # æ­¥é©Ÿ 3: æœå°‹ Mikeon88
    author_links = soup.find_all("a", id=re.compile("lnkName"))
    found_posts = []
    print(f"ğŸ” æƒæ Page {real_page} çš„ç™¼è¨€...")

    for author in author_links:
        author_name = author.get_text(strip=True)
        if "mikeon88" in author_name.lower():
            container = author
            post_content = "ç„¡å…§å®¹"
            post_time = "ç„¡æ™‚é–“"
            
            # å¾€ä¸Šæ‰¾å®¹å™¨
            for _ in range(5):
                if container.parent:
                    container = container.parent
                    body_div = container.find("div", class_="post-body")
                    if body_div:
                        post_content = body_div.get_text("\n", strip=True)
                    
                    # å˜—è©¦æŠ“å–æ™‚é–“ (å¢å¼·ç‰ˆ)
                    t = extract_time(container)
                    if t != "æœªçŸ¥æ™‚é–“":
                        post_time = t
                    
                    if body_div: break
                else: break
            
            if post_content != "ç„¡å…§å®¹":
                found_posts.append({"time": post_time, "content": post_content})

    if not found_posts:
        print("ğŸ’¤ æœ¬é æ²’æœ‰ Mikeon88 çš„ç™¼è¨€")
        save_status(last_fingerprint)
        return

    # æ­¥é©Ÿ 4: é–å®šæœ€æ–°ç™¼è¨€
    latest = found_posts[-1]
    
    print(f"ğŸ” æœ€æ–°ç™¼è¨€æ™‚é–“: {latest['time']}")
    print(f"ğŸ“ å…§å®¹é è¦½: {latest['content'][:30]}...")
    
    current_fingerprint = f"{latest['time']}_{latest['content'][:30]}"
    
    if current_fingerprint != last_fingerprint:
        print(f"ğŸ‰ ç™¼ç¾æ–°å…§å®¹ï¼ç™¼é€é€šçŸ¥...")
        send_discord_notify(latest['content'], latest['time'], target_url)
        save_status(current_fingerprint)
    else:
        print("ğŸ’¤ å…§å®¹èˆ‡ä¸Šæ¬¡ç›¸åŒï¼Œè·³éé€šçŸ¥")
        save_status(last_fingerprint)

if __name__ == "__main__":
    main()
