import requests
from bs4 import BeautifulSoup
import os
import json
import re
from datetime import datetime

# ================= è¨­å®šå€ =================
# å¼·åˆ¶æŒ‡å®šç¬¬ 23 é ï¼Œç§»é™¤ goto åƒæ•¸ï¼Œç¢ºä¿ä¸è·³è½‰å›ç¬¬ä¸€é 
# é€™è£¡ç›´æ¥å¯«æ­» Page 23ï¼Œä¹‹å¾Œç¨‹å¼æœƒè‡ªå·±è™•ç†ç¿»é 
DEFAULT_URL = "https://stocks.ddns.net/Forum/128/mikeon88%E6%8C%81%E8%82%A1%E5%A4%A7%E5%85%AC%E9%96%8B.aspx?page=23"
STATUS_FILE = "status.json"
DISCORD_WEBHOOK_URL = os.environ.get("DISCORD_WEBHOOK")

HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
}
# ==============================================

def send_discord_notify(message_content, post_time, url):
    if not DISCORD_WEBHOOK_URL:
        print("âŒ æœªè¨­å®š Discord Webhook")
        return

    # å…§å®¹æ“·å– (é è¦½)
    preview = message_content[:500] + "..." if len(message_content) > 500 else message_content
    
    data = {
        "username": "Mikeon88 è¿½è¹¤å™¨",
        "embeds": [{
            "title": "ğŸš¨ Mikeon88 æœ‰æ–°ç™¼è¨€ï¼",
            "description": preview,
            "url": url,
            "color": 15158332, # ç´…è‰²ï¼Œä»£è¡¨ç·Šæ€¥/æ–°æ¶ˆæ¯
            "fields": [
                {"name": "ç™¼è¨€æ™‚é–“", "value": post_time, "inline": True},
                {"name": "ä¾†æºé€£çµ", "value": f"[é»æ“Šå‰å¾€]({url})", "inline": True}
            ],
            "footer": {
                "text": "V3 ç²¾æº–é–å®šç‰ˆ"
            }
        }]
    }
    try:
        requests.post(DISCORD_WEBHOOK_URL, json=data)
        print("âœ… Discord é€šçŸ¥å·²ç™¼é€")
    except Exception as e:
        print(f"âŒ ç™¼é€å¤±æ•—: {e}")

def load_status():
    if os.path.exists(STATUS_FILE):
        with open(STATUS_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    return {"current_url": DEFAULT_URL, "last_fingerprint": ""}

def save_status(url, fingerprint):
    with open(STATUS_FILE, "w", encoding="utf-8") as f:
        json.dump({"current_url": url, "last_fingerprint": fingerprint}, f, ensure_ascii=False, indent=4)

def check_for_next_page(soup, current_url):
    try:
        match = re.search(r'page=(\d+)', current_url)
        if not match: return None
        current_page = int(match.group(1))
        
        # å°‹æ‰¾æ‰€æœ‰åˆ†é æŒ‰éˆ•
        page_links = soup.find_all("a", href=True)
        for link in page_links:
            txt = link.text.strip()
            # ç¢ºä¿æ˜¯æ•¸å­—ä¸”å¤§æ–¼ç•¶å‰é ç¢¼
            if txt.isdigit() and int(txt) > current_page:
                new_href = link['href']
                if not new_href.startswith("http"):
                    return "https://stocks.ddns.net" + new_href
                return new_href
    except:
        pass
    return None

def main():
    print(f"ğŸš€ V3 å•Ÿå‹•æª¢æŸ¥: {datetime.now()}")
    
    status = load_status()
    current_url = status["current_url"]
    last_fingerprint = status["last_fingerprint"]
    
    # å®‰å…¨æª¢æŸ¥ï¼šç¢ºä¿ç¶²å€ä¸­æ²’æœ‰å¥‡æ€ªçš„åƒæ•¸å°è‡´è·³å›ç¬¬ä¸€é 
    if "goto=" in current_url:
        print("âš ï¸ åµæ¸¬åˆ°èˆŠçš„è·³è½‰åƒæ•¸ï¼Œé‡ç½®ç‚ºæ¨™æº–åˆ†é ç¶²å€...")
        current_url = DEFAULT_URL

    print(f"ğŸ¯ é–å®šç¶²å€: {current_url}")

    try:
        res = requests.get(current_url, headers=HEADERS, timeout=20)
        res.encoding = 'utf-8'
        if res.status_code != 200:
            print(f"âŒ ç¶²é è®€å–å¤±æ•—: {res.status_code}")
            return

        soup = BeautifulSoup(res.text, "html.parser")

        # 1. è‡ªå‹•ç¿»é æª¢æŸ¥
        next_page = check_for_next_page(soup, current_url)
        if next_page:
            print(f"ğŸš€ ç™¼ç¾æ–°é é¢ (Page Update)ï¼åˆ‡æ›è‡³: {next_page}")
            current_url = next_page
            res = requests.get(current_url, headers=HEADERS)
            res.encoding = 'utf-8'
            soup = BeautifulSoup(res.text, "html.parser")

        # =========================================================
        # V3 æ ¸å¿ƒä¿®æ”¹ï¼šå…ˆæ‰¾äººï¼Œå†æ‰¾æ–‡
        # =========================================================
        
        found_posts = []
        
        # æ ¹æ“šä½ çš„æˆªåœ–1ï¼Œä½œè€…é€£çµæœ‰ id="...lnkName"
        # æˆ‘å€‘æœå°‹æ‰€æœ‰ id åŒ…å« "lnkName" çš„ a æ¨™ç±¤
        author_links = soup.find_all("a", id=re.compile("lnkName"))
        
        print(f"ğŸ” æœ¬é å…±æ‰¾åˆ° {len(author_links)} å€‹ç™¼è¨€è€…ï¼Œé–‹å§‹éæ¿¾ Mikeon88...")

        for author in author_links:
            author_name = author.get_text(strip=True)
            
            # åªæœ‰ç•¶ä½œè€…åå­—çœŸçš„æ˜¯ mikeon88 æ™‚æ‰è™•ç† (å¿½ç•¥å¤§å°å¯«)
            if "mikeon88" in author_name.lower():
                print("âœ… æ‰¾åˆ° Mikeon88 æœ¬äººï¼æ­£åœ¨è§£æå…§å®¹...")
                
                # å¾€ä¸Šæ‰¾å…±åŒçš„å®¹å™¨ (é€šå¸¸æ˜¯ tr æˆ– table æˆ– card div)
                # æˆ‘å€‘å¾€ä¸Šæ‰¾ 4 å±¤ï¼Œæ¯ä¸€å±¤éƒ½è©¦è‘—æ‰¾ post-body
                container = author
                post_content = "ç„¡æ³•è§£æå…§å®¹"
                post_time = "ç„¡æ™‚é–“è³‡è¨Š"
                
                for _ in range(5):
                    if container.parent:
                        container = container.parent
                        
                        # åœ¨é€™å€‹å®¹å™¨è£¡æ‰¾å…§å®¹å€å¡Š (Image 3)
                        body_div = container.find("div", class_="post-body")
                        if body_div:
                            post_content = body_div.get_text("\n", strip=True)
                        
                        # åœ¨é€™å€‹å®¹å™¨è£¡æ‰¾æ™‚é–“ (Image 2)
                        time_span = container.find("span", class_="local-time")
                        if time_span:
                            post_time = time_span.text.strip()
                        
                        # å¦‚æœå…©è€…éƒ½æ‰¾åˆ°ï¼Œæˆ–æ˜¯è‡³å°‘æ‰¾åˆ°äº†å…§å®¹ï¼Œå°±ç•¶ä½œæˆåŠŸ
                        if body_div:
                            break
                    else:
                        break
                
                if post_content != "ç„¡æ³•è§£æå…§å®¹":
                    found_posts.append({"time": post_time, "content": post_content})

        # =========================================================

        if not found_posts:
            print("ğŸ’¤ æœ¬é æ²’æœ‰ Mikeon88 çš„ç™¼è¨€")
            save_status(current_url, last_fingerprint)
            return

        # å–å¾—æœ€å¾Œä¸€ç¯‡ (æœ€æ–°çš„)
        latest = found_posts[-1]
        
        # å»ºç«‹æŒ‡ç´‹
        current_fingerprint = f"{latest['time']}_{latest['content'][:30]}"
        
        print(f"ğŸ” åµæ¸¬åˆ°æœ€æ–°ç™¼è¨€æ™‚é–“: {latest['time']}")
        print(f"ğŸ” å…§å®¹é è¦½: {latest['content'][:30]}...")

        # é€™è£¡åŠ ä¸€å€‹åˆ¤æ–·ï¼šå¦‚æœæ™‚é–“æ˜¯ç©ºçš„ï¼Œå¯èƒ½æ˜¯æŠ“å–å¤±æ•—ï¼Œç‚ºäº†é¿å…èª¤å ±ï¼Œæˆ‘å€‘å¯ä»¥é¸æ“‡ä¸ç™¼é€ï¼Œæˆ–è€…å¼·åˆ¶ç™¼é€
        # ä½†æ—¢ç„¶ä½ ä¹‹å‰çš„æˆªåœ–æ˜¯æœ‰æ™‚é–“çš„ (608è¬é‚£ç¯‡)ï¼Œé€™æ¬¡æ‡‰è©²èƒ½æŠ“åˆ°

        if current_fingerprint != last_fingerprint:
            print(f"ğŸ‰ å…§å®¹èˆ‡ä¸Šæ¬¡ä¸åŒï¼Œç™¼é€é€šçŸ¥ï¼")
            send_discord_notify(latest['content'], latest['time'], current_url)
            save_status(current_url, current_fingerprint)
        else:
            print("ğŸ’¤ å…§å®¹èˆ‡ä¸Šæ¬¡ç›¸åŒï¼Œè·³éé€šçŸ¥")
            save_status(current_url, last_fingerprint)

    except Exception as e:
        print(f"âŒ åš´é‡éŒ¯èª¤: {e}")

if __name__ == "__main__":
    main()
