import requests
from bs4 import BeautifulSoup
import os
import json
import re
from datetime import datetime

# ================= è¨­å®šå€ =================
# æˆ‘å€‘åˆ»æ„æ”¹å›ã€Œç¬¬ä¸€é ã€çš„ç¶²å€ï¼Œè®“ç¨‹å¼è‡ªå·±å»çˆ¬æœ€å¾Œä¸€é åœ¨å“ªè£¡
# é€™æ¨£æœ€æº–ç¢ºï¼Œä¸æœƒå› ç‚ºç¶²å€åƒæ•¸æ‰“éŒ¯è¢«å°å›
ENTRY_URL = "https://stocks.ddns.net/Forum/128/mikeon88%E6%8C%81%E8%82%A1%E5%A4%A7%E5%85%AC%E9%96%8B.aspx"
STATUS_FILE = "status.json"
DISCORD_WEBHOOK_URL = os.environ.get("DISCORD_WEBHOOK")

HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
}
# ==============================================

def send_discord_notify(message_content, post_time, url):
    if not DISCORD_WEBHOOK_URL:
        print("âŒ æœªè¨­å®š Discord Webhook")
        return

    preview = message_content[:300] + "..." if len(message_content) > 300 else message_content
    
    data = {
        "username": "Mikeon88 è¿½è¹¤å™¨",
        "embeds": [{
            "title": "ğŸš¨ Mikeon88 æœ‰æ–°ç™¼è¨€ï¼",
            "description": preview,
            "url": url,
            "color": 15158332, 
            "fields": [
                {"name": "ç™¼è¨€æ™‚é–“", "value": post_time, "inline": True},
                {"name": "ä¾†æºé€£çµ", "value": f"[é»æ“Šå‰å¾€]({url})", "inline": True}
            ],
            "footer": {
                "text": "V4 è‡ªå‹•å°èˆªç‰ˆ"
            }
        }]
    }
    try:
        requests.post(DISCORD_WEBHOOK_URL, json=data)
        print("âœ… Discord é€šçŸ¥å·²ç™¼é€")
    except Exception as e:
        print(f"âŒ ç™¼é€å¤±æ•—: {e}")

def load_status():
    if os.path.exists(STATUS_FILE):
        with open(STATUS_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    return {"last_fingerprint": ""}

def save_status(fingerprint):
    with open(STATUS_FILE, "w", encoding="utf-8") as f:
        json.dump({"last_fingerprint": fingerprint}, f, ensure_ascii=False, indent=4)

def get_real_last_page_url(soup, base_url):
    """
    åˆ†æé é¢ä¸Šçš„åˆ†é æŒ‰éˆ•ï¼Œæ‰¾å‡ºæœ€å¤§çš„é ç¢¼é€£çµ
    """
    print("ğŸ” æ­£åœ¨å°‹æ‰¾æœ€å¾Œä¸€é çš„æŒ‰éˆ•...")
    max_page = 1
    target_url = None
    
    # æŠ“å–æ‰€æœ‰é€£çµ
    links = soup.find_all("a", href=True)
    
    for link in links:
        txt = link.get_text(strip=True)
        href = link['href']
        
        # æƒ…æ³1: é€£çµæ˜¯æ•¸å­— (ä¾‹å¦‚ "23")
        if txt.isdigit():
            page_num = int(txt)
            if page_num > max_page:
                max_page = page_num
                target_url = href
        
        # æƒ…æ³2: é€£çµæ˜¯ ">>" æˆ– "Last" (é€šå¸¸ä»£è¡¨æœ€å¾Œä¸€é )
        elif ">>" in txt or "Last" in txt or "æœ€å¾Œä¸€é " in txt:
            print(f"ğŸ¯ æ‰¾åˆ°ã€æœ€å¾Œä¸€é ã€‘æŒ‰éˆ•ï¼Œç›´æ¥é–å®šï¼")
            target_url = href
            # é€šå¸¸é€™å°±æ˜¯æœ€å¤§é äº†ï¼Œä½†ä¸ä¸€å®šæ˜¯çµ•å°è·¯å¾‘ï¼Œç¨å¾Œè™•ç†
            break
            
    if target_url:
        # è™•ç†ç›¸å°è·¯å¾‘
        if not target_url.startswith("http"):
            target_url = "https://stocks.ddns.net" + target_url
        print(f"ğŸš€ åµæ¸¬åˆ°æœ€å¾Œä¸€é  (Page {max_page})ï¼Œç¶²å€: {target_url}")
        return target_url
    else:
        print("âš ï¸ æ‰¾ä¸åˆ°åˆ†é æŒ‰éˆ•ï¼Œå‡è¨­ç›®å‰å°±æ˜¯æœ€å¾Œä¸€é ")
        return base_url

def main():
    print(f"ğŸš€ V4 å•Ÿå‹•æª¢æŸ¥: {datetime.now()}")
    
    status = load_status()
    last_fingerprint = status["last_fingerprint"]
    
    # æ­¥é©Ÿ 1: å…ˆé€²å…¥å…¥å£é é¢ (é€šå¸¸æ˜¯ç¬¬ä¸€é )
    print(f"1ï¸âƒ£ é€²å…¥å…¥å£é é¢: {ENTRY_URL}")
    try:
        session = requests.Session()
        res = session.get(ENTRY_URL, headers=HEADERS, timeout=20)
        res.encoding = 'utf-8'
        
        if res.status_code != 200:
            print(f"âŒ å…¥å£ç¶²é è®€å–å¤±æ•—: {res.status_code}")
            return

        soup = BeautifulSoup(res.text, "html.parser")
        
        # æ­¥é©Ÿ 2: å°‹æ‰¾ä¸¦è·³è½‰åˆ°ã€ŒçœŸæ­£çš„æœ€å¾Œä¸€é ã€
        real_target_url = get_real_last_page_url(soup, ENTRY_URL)
        
        # å¦‚æœè¨ˆç®—å‡ºçš„ç¶²å€è·Ÿå…¥å£ä¸ä¸€æ¨£ï¼Œå°±è·³è½‰
        if real_target_url != ENTRY_URL:
            print(f"2ï¸âƒ£ è·³è½‰è‡³æœ€å¾Œä¸€é ...")
            res = session.get(real_target_url, headers=HEADERS, timeout=20)
            res.encoding = 'utf-8'
            soup = BeautifulSoup(res.text, "html.parser")
        else:
            print(f"2ï¸âƒ£ ç›®å‰å·²åœ¨ç›®æ¨™é é¢ï¼Œç„¡éœ€è·³è½‰")

        # æ­¥é©Ÿ 3: ç²¾æº–é–å®š Mikeon88 (V3 çš„é‚è¼¯)
        # å°‹æ‰¾æ‰€æœ‰ id åŒ…å« "lnkName" çš„é€£çµ (ä½œè€…å)
        author_links = soup.find_all("a", id=re.compile("lnkName"))
        
        found_posts = []
        print(f"ğŸ” é–‹å§‹æƒæé é¢ä¸Šçš„ç™¼è¨€è€…...")

        for author in author_links:
            author_name = author.get_text(strip=True)
            
            # é–å®š mikeon88
            if "mikeon88" in author_name.lower():
                # å¾€ä¸Šæ‰¾å®¹å™¨
                container = author
                post_content = "ç„¡å…§å®¹"
                post_time = "ç„¡æ™‚é–“"
                
                for _ in range(5):
                    if container.parent:
                        container = container.parent
                        
                        # æ‰¾å…§å®¹
                        body_div = container.find("div", class_="post-body")
                        if body_div:
                            post_content = body_div.get_text("\n", strip=True)
                        
                        # æ‰¾æ™‚é–“
                        time_span = container.find("span", class_="local-time")
                        if time_span:
                            post_time = time_span.text.strip()
                        
                        if body_div: break
                    else: break
                
                if post_content != "ç„¡å…§å®¹":
                    # é€™è£¡å¤šåšä¸€å€‹æª¢æŸ¥ï¼šå¦‚æœæ˜¯ 2023 å¹´çš„èˆŠæ–‡ï¼Œä¸”é é¢ä¸Šæœ‰å…¶ä»–æ–°æ–‡ï¼Œæˆ‘å€‘ä¸è¦é€™ä¸€ç¯‡
                    # ä½†ç°¡å–®èµ·è¦‹ï¼Œæˆ‘å€‘å…ˆå…¨éƒ¨æ”¶é›†èµ·ä¾†ï¼Œæœ€å¾Œåªå–ã€Œæœ€å¾Œä¸€å€‹ã€
                    found_posts.append({"time": post_time, "content": post_content})

        if not found_posts:
            print("ğŸ’¤ æœ¬é æ²’æœ‰ Mikeon88 çš„ç™¼è¨€")
            save_status(last_fingerprint)
            return

        # æ­¥é©Ÿ 4: å–å¾—ã€Œæœ€å¾Œä¸€å‰‡ã€ (The Latest Post)
        # å› ç‚ºè«–å£‡é€šå¸¸æ˜¯ç”±èˆŠåˆ°æ–°æ’åº (æ¨“å±¤åˆ¶)ï¼Œæ‰€ä»¥ List çš„æœ€å¾Œä¸€å€‹å°±æ˜¯æœ€æ–°çš„
        latest = found_posts[-1]
        
        print(f"ğŸ” é–å®šæœ€å¾Œä¸€å‰‡ç™¼è¨€ (å…±æ‰¾åˆ° {len(found_posts)} å‰‡)")
        print(f"ğŸ“… æ™‚é–“: {latest['time']}")
        print(f"ğŸ“ å…§å®¹é–‹é ­: {latest['content'][:20]}...")

        # å»ºç«‹æŒ‡ç´‹
        current_fingerprint = f"{latest['time']}_{latest['content'][:30]}"
        
        if current_fingerprint != last_fingerprint:
            print(f"ğŸ‰ ç™¼ç¾æ–°è²¼æ–‡ (æˆ–åˆæ¬¡åŸ·è¡Œ)ï¼ç™¼é€é€šçŸ¥...")
            send_discord_notify(latest['content'], latest['time'], real_target_url)
            save_status(current_finger
